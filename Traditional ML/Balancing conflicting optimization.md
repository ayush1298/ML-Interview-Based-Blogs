You're in an ML Engineer interview at DoorDash. The interviewer sets a trap:

"Product wants to maximize ğ˜œğ˜´ğ˜¦ğ˜³ ğ˜Šğ˜­ğ˜ªğ˜¤ğ˜¬ğ˜´. Sales wants to maximize ğ˜ğ˜ªğ˜¨ğ˜©-ğ˜Šğ˜°ğ˜®ğ˜®ğ˜ªğ˜´ğ˜´ğ˜ªğ˜°ğ˜¯ ğ˜–ğ˜³ğ˜¥ğ˜¦ğ˜³ğ˜´. How do you design the ğ˜“ğ˜°ğ˜´ğ˜´ ğ˜ğ˜¶ğ˜¯ğ˜¤ğ˜µğ˜ªğ˜°ğ˜¯ to balance these conflicting goals?"

90% of candidates walk right into the trap. They pick up the marker and start writing a custom Loss Function.

They just failed the interview.

Here is why that approach breaks in production, and the architecture that actually gets you hired.

The intuition is to solve the business problem inside the neural network. The candidate proposes a joint loss function:

ğ‹ğ¨ğ¬ğ¬ = Î± * ğ‹ğ¨ğ ğ‹ğ¨ğ¬ğ¬(ğ‚ğ¥ğ¢ğœğ¤) + Î² * ğŒğ’ğ„(ğğ«ğ¨ğŸğ¢ğ­)

They spend 20 minutes explaining how to tune hyperparameter Î± to find the perfect "ğ˜´ğ˜¸ğ˜¦ğ˜¦ğ˜µ ğ˜´ğ˜±ğ˜°ğ˜µ" between user happiness and revenue.

It looks ğ˜®ğ˜¢ğ˜µğ˜©ğ˜¦ğ˜®ğ˜¢ğ˜µğ˜ªğ˜¤ğ˜¢ğ˜­ğ˜­ğ˜º elegant. It is ğ˜°ğ˜±ğ˜¦ğ˜³ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ğ˜¢ğ˜­ğ˜­ğ˜º disastrous.

The moment you hard-code that trade-off into the model weights, you have coupled your engineering infrastructure to quarterly business OKRs.

If the VP of Sales calls you on ğğ¥ğšğœğ¤ ğ…ğ«ğ¢ğğšğ² and says, "We need to boost margins by 10% for the next 6 hours," you are helpless.

To change the balance, you have to:
- Retrain the model with new alpha/beta weights.
- Re-validate the offline metrics.
- Canary deploy the new model.

That is a 3-day pipeline for a 3-hour business requirement.

The Solution: ğ“ğ¡ğ ğƒğğœğ¨ğ®ğ©ğ¥ğğ ğğ›ğ£ğğœğ­ğ¢ğ¯ğ ğğ«ğ¨ğ­ğ¨ğœğ¨ğ¥

The Senior Engineer knows that "ğ‘ğğ¥ğğ¯ğšğ§ğœğ" is a physics problem (what the user wants), but "ğğ«ğ¢ğ¨ğ«ğ¢ğ­ğ²" is a business problem (what the company wants).
You do not bake business logic into model weights. You solve this at the ğ’ğğ«ğ¯ğ¢ğ§ğ  ğ‹ğšğ²ğğ«.

- ğ˜”ğ˜°ğ˜¥ğ˜¦ğ˜­ ğ˜ˆ (ğ˜›ğ˜©ğ˜¦ ğ˜‰ğ˜³ğ˜¢ğ˜ªğ˜¯): Trains purely on P(Click) or P(Conversion). It knows nothing about money.
- ğ˜›ğ˜©ğ˜¦ ğ˜šğ˜ªğ˜¨ğ˜¯ğ˜¢ğ˜­ (ğ˜›ğ˜©ğ˜¦ ğ˜Šğ˜°ğ˜¯ğ˜µğ˜¦ğ˜¹ğ˜µ): You fetch the Commission_Rate from your feature store.
- ğ˜›ğ˜©ğ˜¦ ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯: You combine them strictly at the final ranking stage using a lightweight algebraic formula:
ğ…ğ¢ğ§ğšğ¥_ğ’ğœğ¨ğ«ğ = (ğ°1 * ğŒğ¨ğğğ¥_ğğ«ğğğ¢ğœğ­ğ¢ğ¨ğ§) + (ğ°2 * ğ‚ğ¨ğ¦ğ¦ğ¢ğ¬ğ¬ğ¢ğ¨ğ§_ğğ¨ğ«ğ¦ğšğ¥ğ¢ğ³ğğ)

Now, when business priorities shift, you don't retrain a neural network. You update a single config file in your serving infrastructure: 
w2: 0.2 -> 0.4

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:
"We don't use ML to learn the trade-off. We use ML to learn the probabilities, and we define the trade-off dynamically at runtime."
