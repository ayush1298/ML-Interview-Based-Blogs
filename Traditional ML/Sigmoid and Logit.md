Logit() and Sigmoid()
The logit function maps probabilities to the full range of real numbers required prior to modeling.

The inverse of the logit function is the sigmoid function. That is, if you have a probability p, sigmoid(logit(p)) = p. The sigmoid function maps arbitrary real values back to the range [0, 1]. We can also say sigmoid function as the generalized form of logit function.

---

### ğŸ”¹ Step 1: The two functions

We have two mathematical functions:

1ï¸âƒ£ **Sigmoid (or logistic) function:**
[
\sigma(x) = \frac{1}{1 + e^{-x}}
]
It takes **any real number** and **squashes it** into a range between **0 and 1**, so it looks like a smooth â€œSâ€ curve.

ğŸ‘‰ Input: real numbers (-âˆ to âˆ)
ğŸ‘‰ Output: probabilities (0 to 1)

---

2ï¸âƒ£ **Logit function (inverse of sigmoid):**
[
\text{logit}(p) = \ln\left(\frac{p}{1 - p}\right)
]
It takes **a probability** (something between 0 and 1) and **expands** it back into **the whole real line (-âˆ to âˆ)**.

ğŸ‘‰ Input: probability (0 to 1)
ğŸ‘‰ Output: real numbers (-âˆ to âˆ)

---

### ğŸ”¹ Step 2: How they are inverses

Think of this like **a reversible transformation** between real numbers and probabilities:

| Real value (x) | Sigmoid(x) = probability (p) | Logit(p) = x |
| -------------- | ---------------------------- | ------------ |
| -âˆ             | 0                            | -âˆ           |
| 0              | 0.5                          | 0            |
| +âˆ             | 1                            | +âˆ           |

If you take a probability ( p ), apply **logit(p)**, and then apply **sigmoid()**, you get back the same ( p ):
[
\sigma(\text{logit}(p)) = p
]
and if you take a real value ( x ), apply **sigmoid(x)**, and then **logit()**, you get back ( x ):
[
\text{logit}(\sigma(x)) = x
]

---

### ğŸ”¹ Step 3: Why this matters in modeling

In **logistic regression**, we need to model probabilities, but we canâ€™t directly fit a regression line to numbers between 0 and 1 â€” it could predict values outside that range.

So, we:

1. Use **logit(p)** to transform probabilities into **real numbers** (the â€œlog-oddsâ€).
2. Fit a **linear model** on these real numbers (since linear models work well on unrestricted values).
3. Then, to interpret predictions as probabilities again, we apply the **sigmoid** to the model output.

---

### ğŸ”¹ Step 4: Simple analogy

Think of it like:

* **Sigmoid:** squeezes any real number into a â€œprobability boxâ€ (0â€“1).
* **Logit:** unwraps a probability out of that box, stretching it back to the whole real line.

---
