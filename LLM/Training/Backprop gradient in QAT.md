You're in a Senior AI Engineer interview at Meta and the interviewer drops this on you:

"We need to switch to ğğ®ğšğ§ğ­ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ ğ€ğ°ğšğ«ğ ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ  (ğğ€ğ“) because post-training quantization is tanking our accuracy. But the rounding operation (Float -> Int8) is a step function with a derivative of zero. How do you actually backpropagate gradients through it to update the weights?"

90% of candidates walk right into the trap.

Most candidates immediately answer: "You can't backpropagate through a step function. It's non-differentiable, so the gradients vanish to zero."

Technically true, but useless. If they stop here, the interview is over. They have just explained why the model won't learn, not how to fix it.

The reality of QAT is that ğ˜¸ğ˜¦ ğ˜©ğ˜¢ğ˜·ğ˜¦ ğ˜µğ˜° "ğ˜­ğ˜ªğ˜¦" ğ˜µğ˜° ğ˜µğ˜©ğ˜¦ ğ˜°ğ˜±ğ˜µğ˜ªğ˜®ğ˜ªğ˜»ğ˜¦ğ˜³.

If you use the actual derivative of the rounding function, your gradient is 0 everywhere (flat) or undefined (at the step). The signal dies immediately.

To fix this in production, we use the ğ’ğ­ğ«ğšğ¢ğ ğ¡ğ­ ğ“ğ¡ğ«ğ¨ğ®ğ ğ¡ ğ„ğ¬ğ­ğ¢ğ¦ğšğ­ğ¨ğ« (ğ’ğ“ğ„).

Here is the mechanism you need to explain:
1ï¸âƒ£ ğ˜›ğ˜©ğ˜¦ ğ˜ğ˜°ğ˜³ğ˜¸ğ˜¢ğ˜³ğ˜¥ ğ˜—ğ˜¢ğ˜´ğ˜´ (ğ˜›ğ˜©ğ˜¦ ğ˜›ğ˜³ğ˜¶ğ˜µğ˜©): We apply the quantization (rounding). The loss is calculated using the discrete, "snapped" values. This ensures the model feels the pain of quantization errors.
2ï¸âƒ£ ğ˜›ğ˜©ğ˜¦ ğ˜‰ğ˜¢ğ˜¤ğ˜¬ğ˜¸ğ˜¢ğ˜³ğ˜¥ ğ˜—ğ˜¢ğ˜´ğ˜´ (ğ˜›ğ˜©ğ˜¦ ğ˜“ğ˜ªğ˜¦): When calculating gradients, we ignore the rounding function entirely. We approximate its derivative as the Identity Function (1).

Think of it like walking up a staircase:
- ğ˜ğ˜°ğ˜³ğ˜¸ğ˜¢ğ˜³ğ˜¥: You step on the hard, discrete stairs.
- ğ˜‰ğ˜¢ğ˜¤ğ˜¬ğ˜¸ğ˜¢ğ˜³ğ˜¥: You pretend it was a smooth ramp so you can slide the gradient information back down without hitting a wall.

We accept a "ğ˜¨ğ˜³ğ˜¢ğ˜¥ğ˜ªğ˜¦ğ˜¯ğ˜µ ğ˜®ğ˜ªğ˜´ğ˜®ğ˜¢ğ˜µğ˜¤ğ˜©", the gradient doesn't perfectly match the forward operation, because a noisy gradient is infinitely better than a zero gradient.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:
"We decouple the passes. We use the quantized weights in the forward pass to simulate inference precision, but we apply the Straight Through Estimator in the backward pass, treating the rounding operation as an identity function to keep the gradients flowing to the learnable full-precision weights."
