You're in a GenAI Engineer interview at NVIDIA, and the interviewer asks:
"We're deploying a 13B parameter. Should we use FP16 or BF16? Justify your choice."

Here's how you can answer:
A. Most candidates say "BF16 is better for training, FP16 for inference." Superficial answer.
B. There are 4 critical factors every GenAI engineer should understand cold.

ðŸ­. ð—§ð—µð—² ð—¡ð˜‚ð—ºð—²ð—¿ð—¶ð—°ð—®ð—¹ ð—¥ð—²ð—½ð—¿ð—²ð˜€ð—²ð—»ð˜ð—®ð˜ð—¶ð—¼ð—» - ð—§ð—µð—² ð—³ð˜‚ð—»ð—±ð—®ð—ºð—²ð—»ð˜ð—®ð—¹ ð—®ð—¿ð—°ð—µð—¶ð˜ð—²ð—°ð˜ð˜‚ð—¿ð—²
FP16 (Half Precision):

1 sign bit, 5 exponent bits, 10 mantissa bits
Range: Â±65,504 (narrow dynamic range)
Precision: ~3 decimal digits

BF16 (Brain Float 16):

1 sign bit, 8 exponent bits, 7 mantissa bits
Range: Â±3.4 Ã— 10Â³â¸ (SAME as FP32)
Precision: ~2 decimal digits

The brutal truth? FP16 gives better precision. BF16 gives better range.

ðŸ®. ð—§ð—µð—² ð—¢ð˜ƒð—²ð—¿ð—³ð—¹ð—¼ð˜„/ð—¨ð—»ð—±ð—²ð—¿ð—³ð—¹ð—¼ð˜„ ð—¥ð—¶ð˜€ð—¸ - ð—ªð—µð—²ð—¿ð—² ðŸ´ðŸ±% ð—¼ð—³ ð—²ð—»ð—´ð—¶ð—»ð—²ð—²ð—¿ð˜€ ð—´ð—²ð˜ ð—¯ð˜‚ð—¿ð—»ð—²ð—±
Most people think "FP16 and BF16 are interchangeable."
Wrong move.
FP16's nightmare scenario:

Max value: 65,504
Gradient explosions during training â†’ NaN
Requires loss scaling (1024x-32768x typical)
Attention logits can EASILY overflow

BF16's advantage:

Max value: 3.4 Ã— 10Â³â¸ (FP32 range)
Drop-in replacement for FP32 â†’ NO loss scaling needed
Direct truncation from FP32 (just chop 16 bits)

Real-world impact? Training Llama 2 70B in FP16 = gradient explosion hell. BF16 = smooth sailing.

ðŸ¯. ð—§ð—µð—² ð—›ð—®ð—¿ð—±ð˜„ð—®ð—¿ð—² ð—¦ð˜‚ð—½ð—½ð—¼ð—¿ð˜ - ð—§ð—µð—² ð—µð—¶ð—±ð—±ð—²ð—» ð—½ð—¿ð—¼ð—±ð˜‚ð—°ð˜ð—¶ð—¼ð—» ð—¸ð—¶ð—¹ð—¹ð—²ð—¿
Here's what separates junior from senior GenAI engineers:

FP16 Hardware:
Universal support: V100, T4, A100, H100, ALL GPUs

BF16 Hardware:
Ampere+ only (A100, H100, RTX 3090+)

The counterintuitive reality? BF16 on V100 = 4x slower than FP16. Hardware matters MORE than format.

ðŸ°. ð—§ð—µð—² ð—§ð—¿ð—®ð—¶ð—»ð—¶ð—»ð—´ ð˜ƒð˜€ ð—œð—»ð—³ð—²ð—¿ð—²ð—»ð—°ð—² ð—§ð—¿ð—®ð—±ð—² - ð—§ð—µð—² ð—°ð—¼ð˜€ð˜ ð—»ð—¼ð—¯ð—¼ð—±ð˜† ð˜ð—®ð—¹ð—¸ð˜€ ð—®ð—¯ð—¼ð˜‚ð˜
Training (backward pass matters):

BF16 wins 90% of the time
No loss scaling complexity
Stable gradient updates
Industry standard: GPT-3, Llama 2, Stable Diffusion

Inference (forward pass only):

FP16 often superior
Better precision for final predictions
Wider hardware compatibility
Lower memory bandwidth on older GPUs

Mixed Precision Reality:

Store weights in BF16/FP16
Compute in FP32 for critical ops (softmax, LayerNorm)
Master weights in FP32 (training only)


ð—ªð—µð—²ð—» ð—™ð—£ðŸ­ðŸ² ð˜„ð—¶ð—»ð˜€:
âœ… Inference on edge devices (Jetson, mobile)
âœ… V100/T4 deployment (no BF16 support)
âœ… Vision models with bounded value ranges
âœ… Maximum precision critical (scientific computing)

ð—ªð—µð—²ð—» ð—•ð—™ðŸ­ðŸ² ð˜„ð—¶ð—»ð˜€:
âœ… Training large models (7B+ parameters)
âœ… Long-context scenarios (8K+ tokens)
âœ… A100/H100 hardware available
âœ… Training stability > precision
âœ… Drop-in FP32 replacement needed

Difference table:
<img width="676" height="340" alt="image" src="https://github.com/user-attachments/assets/67ec5a0c-97fa-4d87-9bcf-64cb9f832459" />


Extra reading:
https://medium.com/@furkangozukara/what-is-the-difference-between-fp16-and-bf16-here-a-good-explanation-for-you-d75ac7ec30fa
