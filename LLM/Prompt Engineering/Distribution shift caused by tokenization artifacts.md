You're in an AI Engineer interview at Meta and the interviewer asks:

"We deployed a Llama-3 based app. We removed a single whitespace in the prompt template, and our benchmark accuracy tanked by 12%. Why is the model so brittle to a simple format change, and why didn't instruction tuning prevent this?"

Donâ€™t say: "The model is confused by the bad grammar."

Too vague. This is the junior answer. The model has read the entire internet, it has seen typos before.

The reality is that LLMs do not read text. They process sequences of integers.
When you delete a whitespace or a colon, you aren't just making a "typo", you are fundamentally altering the ğ“ğ¨ğ¤ğğ§ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ ğğ¨ğ®ğ§ğğšğ«ğ².

Here is the production-level breakdown:
1ï¸âƒ£ ğ“ğ¡ğ ğ“ğ¨ğ¤ğğ§ğ¢ğ³ğğ« ğ“ğ«ğšğ©: In many tokenizers, " word" (with a leading space) and "word" (without) map to completely different integer IDs. To the model, they are as distinct as "apple" and "orange." You just broke the integer sequence the model optimized for.

2ï¸âƒ£ ğ’ğ©ğ®ğ«ğ¢ğ¨ğ®ğ¬ ğ‚ğ¨ğ«ğ«ğğ¥ğšğ­ğ¢ğ¨ğ§ğ¬: The model often relies on "spurious features", shortcuts in the training data. It might have learned that ğ˜˜ğ˜¶ğ˜¦ğ˜´ğ˜µğ˜ªğ˜°ğ˜¯: [ğ˜Šğ˜°ğ˜¯ğ˜µğ˜¦ğ˜¹ğ˜µ] predicts an answer, but ğ˜˜ğ˜¶ğ˜¦ğ˜´ğ˜µğ˜ªğ˜°ğ˜¯ [ğ˜Šğ˜°ğ˜¯ğ˜µğ˜¦ğ˜¹ğ˜µ] (no colon) implies a continuation or a grammar correction task.

3ï¸âƒ£ ğ“ğ¡ğ ğˆğ§ğ¬ğ­ğ«ğ®ğœğ­ğ¢ğ¨ğ§ ğ“ğ®ğ§ğ¢ğ§ğ  ğ…ğšğ¥ğ¥ğšğœğ²: Theoretically, ğ˜ğ˜¯ğ˜´ğ˜µğ˜³ğ˜¶ğ˜¤ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜›ğ˜¶ğ˜¯ğ˜ªğ˜¯ğ˜¨ (ğ˜™ğ˜“ğ˜ğ˜/ğ˜šğ˜ğ˜›) fixes this by teaching the model to follow intent.
- If the instruction tuning data only used one specific template (e.g., specific XML tags or chat headers), the model overfits to that specific structure.
- By changing the format, you effectively pushed the input Out-Of-Distribution (OOD) for the instruction-tuned head.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:
"It's not a grammar issue, it's a distribution shift caused by tokenization artifacts. The model latched onto specific formatting tokens as strong features during SFT. To fix this in production, we shouldn't just tweak prompts manually, we need to use ğ€ğ®ğ­ğ¨ğ¦ğšğ­ğğ ğğ«ğ¨ğ¦ğ©ğ­ ğğ©ğ­ğ¢ğ¦ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ (ğ€ğğ) or verify our inputs against the exact chat template the model was fine-tuned on."
