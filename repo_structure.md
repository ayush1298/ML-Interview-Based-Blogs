.
├── _config.yml
├── _includes
│   ├── footer.html
│   └── header.html
├── _layouts
│   ├── article.html
│   └── default.html
├── Agents
│   ├── How Agnets are different from chatbot?.md
│   ├── Long-term vs. Short-term memory in agentic trading assistant.md
│   ├── Memory in Agents.md
│   ├── Short-term vs long-term memory preferences.md
│   ├── Termination Problem in Agents.md
│   └── Why do tool-using agents often hallucinate function calls even when APIs are available?.md
├── assets
│   ├── css
│   │   └── style.css
│   ├── images
│   └── js
│       ├── main.js
│       └── markdown-viewer.js
├── catalog.json
├── Computer Vision
│   ├── Diffusion steps with low-resolution images.md
│   └── How to use tranformation in case of data sparsity.md
├── Gemfile
├── index.html
├── LLM
│   ├── Attention
│   │   ├── Attention Mechanism choice for serving 70B LLM.md
│   │   ├── d_model in positional embeddings vs. d_k in attention.md
│   │   ├── Linear vs. Sparse Attention.md
│   │   └── Why do we divide by √dₖ instead of √d? .md
│   ├── Context_Window
│   │   └── Context_Window_issue.md
│   ├── Data
│   │   └── Data for LLM-training.md
│   ├── Evals
│   │   └── How evals are done.md
│   ├── Finetuning
│   │   ├── Finetune model directly on user prompts.md
│   │   ├── Intializing matrix weights in LORA.md
│   │   ├── LORA.md
│   │   └── SFT vs GRPO for complex legal reasoning model.md
│   ├── GPU Utilization
│   │   └── Tradeoff between TTFT and batch summarization in Chatbot.md
│   ├── Inference
│   │   ├── Fusion of Thinking and Non-thinking Model.md
│   │   ├── How increasing batch size affects costs, latency and throughput?.md
│   │   ├── How increasing either model depth or width by 2x affects latency, cost and accuracy
│   │   ├── Implementing GRPO and reward hacking trap.md
│   │   ├── Inference speed of MHA vs. GQA.md
│   │   ├── LLM Serving Frameworks.md
│   │   ├── Paged Attention
│   │   │   └── Paged Attention1.md
│   │   └── Speculative Decoding
│   │       └── Speculative Decoding1.md
│   ├── Other General Questions
│   │   ├── Catstophic forgetting and how to solve it?.md
│   │   ├── Difference between Layer normalization and batch normalization & why transformer uses layer and not batchnorm?.md
│   │   ├── Hallucination in LLMs.md
│   │   ├── LLM Parameters and Memory Estimation.md
│   │   └── Transformer-based regression model for home sales predictions.md
│   ├── Positional Embedding
│   │   ├── How ROPE is different from sin-cos positional embeddings.md
│   │   └── ROPE Positional Embedding.md
│   ├── Prompt Engineering
│   │   └── Prompt Drift Problem.md
│   ├── Quantization
│   │   ├── FP16 vs BF16, Which one to use?.md
│   │   ├── QAT vs. MPT.md
│   │   ├── Quantization from FP16 to INT8.md
│   │   ├── temp.md
│   │   └── Which one is to use? 4-bit vs 8-bit for production trading signals.md
│   ├── Tokenization
│   │   ├── Adjusting tokenizer of 1 language to other language.md
│   │   ├── Tokenizer_for_training_domain_specialized_LLMs.md
│   │   └── Why BPE tokenizer over traditional byte-based tokenizer?.md
│   └── Training
│       ├── Change in LR as LLM model size changes.md
│       ├── Finding optimal LR while scaling 1B model to 70B model.md
│       ├── Fixed Compute Budget- Best Model Training.md
│       ├── Fixing gradient oscillation and loss spikes during LLM training.md
│       ├── Training_Instability_Exploding_Gradients_Deeper_LLM.md
│       ├── Training_stability_in_Shallow_LLMs.md
│       └── Warmup+Decay phase in LLM training.md
├── Neural Network
│   ├── DL Layer Summary.md
│   ├── How to use Droput layer during inference?.md
│   ├── Training run budget of Neural Network.md
│   ├── Weight intialization techniques in NN.md
│   └── Why tranformers win over RNN and LSTM for sequence modlling?.md
├── RAG
│   ├── RAG vs CAG.md
│   └── Vector DB for RAG.md
├── repo_structure.md
├── scripts
│   └── generate_catalog.py
├── Statistics
│   └── Hypothesis Testing
│       └── How to decide which tests to use when?.md
├── System Design
│   ├── How often should we retrain recommendation model?.md
│   └── LLM_System Design.pdf
├── Traditional ML
│   ├── Balancing conflicting optimization.md
│   ├── Class Imbalance for fraud detection.md
│   ├── Convex vs Non-Convex Loss Function.md
│   ├── Interpreting Coefficients in Logistic Regression.md
│   ├── Metric for fraud detection model.md
│   ├── Reservoir Samping when value of sample is large.md
│   ├── Sigmoid and Logit.md
│   └── What to use in bagging and boosting for production credit risk model.md
└── view.html

32 directories, 83 files
