Your ğ˜Šğ˜­ğ˜ªğ˜¤ğ˜¬-ğ˜›ğ˜©ğ˜³ğ˜°ğ˜¶ğ˜¨ğ˜© ğ˜™ğ˜¢ğ˜µğ˜¦ğ˜´ is hitting all-time highs. Your retraining pipeline is executing perfectly every 24 hours. But user retention is quietly tanking.

The VP of Engineering asks the candidate why your "successful" model is killing the product.

If they answer "Maybe the content quality dropped," they just failed the interview.

The intuitive reaction is to celebrate the metrics. The candidates see high ğ˜Šğ˜­ğ˜ªğ˜¤ğ˜¬-ğ˜›ğ˜©ğ˜³ğ˜°ğ˜¶ğ˜¨ğ˜© ğ˜™ğ˜¢ğ˜µğ˜¦ğ˜´ (ğ˜Šğ˜›ğ˜™) and assume the model has cracked the code on user intent. They take those millions of new clicks, feed them back into the training set, and push a new model version that biases even harder toward those winning items.

ğ˜›ğ˜©ğ˜¦ğ˜º ğ˜¢ğ˜´ğ˜´ğ˜¶ğ˜®ğ˜¦: ğ˜ğ˜ªğ˜¨ğ˜© ğ˜Œğ˜¯ğ˜¨ğ˜¢ğ˜¨ğ˜¦ğ˜®ğ˜¦ğ˜¯ğ˜µ = ğ˜ğ˜ªğ˜¨ğ˜© ğ˜“ğ˜¦ğ˜¢ğ˜³ğ˜¯ğ˜ªğ˜¯ğ˜¨.

But they aren't optimizing for preference. They are optimizing for availability.

Users can only click on what you show them. If your model thinks "ğ€ğœğ­ğ¢ğ¨ğ§ ğŒğ¨ğ¯ğ¢ğğ¬" are the winner and fills the carousel with them, users will click ğ€ğœğ­ğ¢ğ¨ğ§ ğŒğ¨ğ¯ğ¢ğğ¬. Not because they love them, but because they have no other choice.

When we retrain on this data, we aren't teaching the model what users want.

We are teaching the model to predict its own past decisions.

The Solution: ğ“ğ¡ğ ğ„ğœğ¡ğ¨ ğ‚ğ¡ğšğ¦ğ›ğğ« ğ‚ğ¨ğ¥ğ¥ğšğ©ğ¬ğ

We have created a degenerate feedback loop. By training on our own production logs without correction, we systematically prune the feature space. The model becomes overconfident in a narrowing slice of content, eventually boring users to death.

To fix this, we need ğ‚ğ¨ğ®ğ§ğ­ğğ«ğŸğšğœğ­ğ®ğšğ¥ ğ„ğ¯ğšğ¥ğ®ğšğ­ğ¢ğ¨ğ§.

- ğ„ğ±ğ©ğ¥ğ¨ğ«ğšğ­ğ¢ğ¨ğ§ ğ¢ğ¬ ğ¦ğšğ§ğğšğ­ğ¨ğ«ğ²: You must sacrifice short-term CTR for long-term data health. Dedicate a slice of traffic (e.g., Îµ-greedy strategy ) to show random or uncertain items. This generates the "negative labels" your model desperately needs to learn boundaries.
- ğƒğğ›ğ¢ğšğ¬ ğ­ğ¡ğ ğ°ğğ¢ğ ğ¡ğ­ğ¬: Apply ğˆğ§ğ¯ğğ«ğ¬ğ ğğ«ğ¨ğ©ğğ§ğ¬ğ¢ğ­ğ² ğ–ğğ¢ğ ğ¡ğ­ğ¢ğ§ğ  (ğˆğğ–) during training. Downweight clicks that happened simply because an item was in Position 1, and upweight clicks that happened despite an item being buried.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:
"A model that only learns from its own uncorrected predictions is destined to collapse. We don't just optimize for clicks today; we optimize for the informational value of the training data we generate for tomorrow."
