You're in a Senior ML Interview at OpenAI. The interviewer sets a trap:

"We have 50 000 images of 'city streets' but only 45 images of 'deer at night.' How do we fix this ğ‚ğ¥ğšğ¬ğ¬ ğˆğ¦ğ›ğšğ¥ğšğ§ğœğ to prevent the model from ignoring the deer?"

90% of candidates walk right into the trap.

They say "I will ramp up the data augmentation pipeline." Then they start listing standard ğ˜µğ˜°ğ˜³ğ˜¤ğ˜©ğ˜·ğ˜ªğ˜´ğ˜ªğ˜°ğ˜¯ transforms: ğ˜™ğ˜¢ğ˜¯ğ˜¥ğ˜°ğ˜®ğ˜ğ˜°ğ˜³ğ˜ªğ˜»ğ˜°ğ˜¯ğ˜µğ˜¢ğ˜­ğ˜ğ˜­ğ˜ªğ˜±, ğ˜™ğ˜¢ğ˜¯ğ˜¥ğ˜°ğ˜®ğ˜™ğ˜°ğ˜µğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯(30), ğ˜Šğ˜°ğ˜­ğ˜°ğ˜³ğ˜‘ğ˜ªğ˜µğ˜µğ˜¦ğ˜³, and maybe ğ˜”ğ˜°ğ˜´ğ˜¢ğ˜ªğ˜¤ ğ˜¢ğ˜¶ğ˜¨ğ˜®ğ˜¦ğ˜¯ğ˜µğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯.

It feels like the correct, robust MLOps answer.

The interviewer nods, notes "You just trained the model to recognize those same 45 deer upside-down and slightly greener." and moves on.

Here is the failure mode: ğ˜šğ˜µğ˜¢ğ˜¯ğ˜¥ğ˜¢ğ˜³ğ˜¥ ğ˜¨ğ˜¦ğ˜°ğ˜®ğ˜¦ğ˜µğ˜³ğ˜ªğ˜¤ ğ˜±ğ˜¦ğ˜³ğ˜µğ˜¶ğ˜³ğ˜£ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ğ˜´ ğ˜±ğ˜³ğ˜°ğ˜·ğ˜ªğ˜¥ğ˜¦ ğ˜ğ˜¯ğ˜·ğ˜¢ğ˜³ğ˜ªğ˜¢ğ˜¯ğ˜¤ğ˜¦, ğ˜¯ğ˜°ğ˜µ ğ˜‹ğ˜ªğ˜·ğ˜¦ğ˜³ğ˜´ğ˜ªğ˜µğ˜º.

A rotated deer is still the exact same instance of a deer. The candidates aren't adding new high-level semantic information (fur patterns, body shapes, poses). They are just adding noise to the existing low-level pixels.

They cannot augment their way out of a semantic deficit with geometric tricks.

-----
ğ“ğ¡ğ ğ’ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§: To pass, you need to propose ğ’ğğ¦ğšğ§ğ­ğ¢ğœ ğ’ğ²ğ§ğ­ğ¡ğğ¬ğ¢ğ¬.

Instead of manipulating the pixels, you manipulate the latent space.

1ï¸âƒ£ ğ˜›ğ˜©ğ˜¦ ğ˜—ğ˜ªğ˜±ğ˜¦ğ˜­ğ˜ªğ˜¯ğ˜¦: Use a conditional generative model (like Stable Diffusion or a fine-tuned LoRA) in an Image-to-Image workflow.
2ï¸âƒ£ ğ˜›ğ˜©ğ˜¦ ğ˜”ğ˜¦ğ˜µğ˜©ğ˜°ğ˜¥: Take your abundant "empty street at night" images. Use the generative model to "inpaint" or synthesize deer into those existing, real-world lighting contexts.
3ï¸âƒ£ ğ˜›ğ˜©ğ˜¦ ğ˜™ğ˜¦ğ˜´ğ˜¶ğ˜­ğ˜µ: You aren't just rotating a deer; you are creating new deer. New poses, new interactions with shadows, and new occlusions that never existed in the training set.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:

"Geometric augmentation solves for robust features (noise tolerance). Generative synthesis solves for distribution shifts (semantic gaps). In a data-starved regime, we need synthesis, not just rotation."
