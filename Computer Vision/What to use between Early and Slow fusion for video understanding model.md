You're in a Computer Vision Engineer interview at Meta and the interviewer drops this on you:

"We're debating between ğ˜Œğ˜¢ğ˜³ğ˜­ğ˜º ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯ and ğ˜šğ˜­ğ˜°ğ˜¸ ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯ for our new video understanding model. Everyone knows ğ˜šğ˜­ğ˜°ğ˜¸ ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯ captures motion better, but what is the specific computational consequence of maintaining that temporal dimension through multiple layers that kills our training budget?"

Don't say: "ğ˜šğ˜­ğ˜°ğ˜¸ ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯ is slower because 3D convolutions are just more complex than 2D convolutions."

Technically true, but it misses the actual bottleneck.

The real killer isn't just the operation complexity, it's the feature map volume explosion.

When you do ğ˜Œğ˜¢ğ˜³ğ˜­ğ˜º ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯, you collapse the temporal dimension (T) immediately in the first layer. Youâ€™re essentially turning a video into an image instantly. Your subsequent feature maps are just H x W x C.

In ğ˜šğ˜­ğ˜°ğ˜¸ ğ˜ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯, you are maintaining that T dimension deep into the network.
1ï¸âƒ£ ğ“ğ¡ğ ğŒğğ¦ğ¨ğ«ğ² ğ“ğ«ğšğ©: You aren't just storing weights; you are storing activations for every single time step across multiple layers.

2ï¸âƒ£ ğ“ğ¡ğ ğğšğ§ğğ°ğ¢ğğ­ğ¡ ğ›ğ¨ğ­ğ­ğ¥ğğ§ğğœğ¤: Your GPU memory fills up with intermediate activations, forcing you to drastically reduce batch size.

3ï¸âƒ£ ğ“ğ¡ğ ğ‘ğğ¬ğ®ğ¥ğ­: You might get better accuracy, but your throughput tanks because you're moving massive 4D tensors (T x H x W x C) through memory instead of compact 3D ones.

It's like trying to photocopy a book by photocopying every single page individually versus just photocopying the summary on the back cover. One is 100x more data to manage.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:

"The bottleneck is the activation memory footprint. By maintaining temporal resolution through intermediate layers, we increase the volume of stored activations by a factor of T, which forces smaller batch sizes and destroys parallelization efficiency on the GPU."
