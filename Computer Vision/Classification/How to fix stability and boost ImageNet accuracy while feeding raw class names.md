You're in a Senior Computer Vision interview at OpenAI. The interviewer sets a trap:

"We just deployed a CLIP model for zero-shot classification. We're feeding in raw class names like ğ˜¥ğ˜°ğ˜¨ or ğ˜±ğ˜­ğ˜¢ğ˜¯ğ˜¦ as text prompts. The accuracy is shaky and the variance is high. Without retraining a single parameter, ğ¡ğ¨ğ° ğğ¨ ğ²ğ¨ğ® ğŸğ¢ğ± ğ­ğ¡ğ ğ¬ğ­ğšğ›ğ¢ğ¥ğ¢ğ­ğ² ğšğ§ğ ğ›ğ¨ğ¨ğ¬ğ­ ğˆğ¦ğšğ ğğğğ­ ğšğœğœğ®ğ«ğšğœğ²?"

90% of candidates walk right into the trap.

Most say: "Just change the prompt to ğ˜ˆ ğ˜±ğ˜©ğ˜°ğ˜µğ˜° ğ˜°ğ˜§ ğ˜¢ [ğ˜¤ğ˜­ğ˜¢ğ˜´ğ˜´]."

It's not wrong, it helps, but it reveals they treat ğ…ğ¨ğ®ğ§ğğšğ­ğ¢ğ¨ğ§ ğŒğ¨ğğğ¥ğ¬ like magic black boxes rather than ğ˜©ğ˜ªğ˜¨ğ˜©-ğ˜¥ğ˜ªğ˜®ğ˜¦ğ˜¯ğ˜´ğ˜ªğ˜°ğ˜¯ğ˜¢ğ˜­ ğ˜·ğ˜¦ğ˜¤ğ˜µğ˜°ğ˜³ ğ˜´ğ˜±ğ˜¢ğ˜¤ğ˜¦ğ˜´. They are betting your production metrics on a single point in latent space.

The Senior Engineer knows that in high-dimensional space, a single text embedding is noisy. ğ˜‹ğ˜°ğ˜¨ could mean a pet, a hot dog, or a friend. Even ğ˜ˆ ğ˜±ğ˜©ğ˜°ğ˜µğ˜° ğ˜°ğ˜§ ğ˜¢ ğ˜¥ğ˜°ğ˜¨ is just one vector direction.

To pass this interview, you need to mention ğ“ğ¡ğ ğ‚ğğ§ğ­ğ«ğ¨ğ¢ğ ğ’ğ­ğšğ›ğ¢ğ¥ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ ğğ«ğ¨ğ­ğ¨ğœğ¨ğ¥.

We don't want the vector for a specific sentence. We want the mean vector that represents the concept itself, robust to linguistic noise.

-----
ğ“ğ¡ğ ğ’ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§:
1ï¸âƒ£ ğ˜ğ˜¦ğ˜¯ğ˜¦ğ˜³ğ˜¢ğ˜µğ˜¦ ğ˜ğ˜¢ğ˜³ğ˜ªğ˜¢ğ˜¯ğ˜¤ğ˜¦: Don't create one prompt. Create 80+ distinct templates:
- "A photo of a {class}."
- "A sketch of a {class}."
- "A low-resolution image of a {class}."

2ï¸âƒ£ ğ˜‰ğ˜¢ğ˜µğ˜¤ğ˜© ğ˜Œğ˜¯ğ˜¤ğ˜°ğ˜¥ğ˜¦: Run all 80 prompts through the Text Encoder to get 80 distinct vectors (N x D).

3ï¸âƒ£ ğ˜ˆğ˜·ğ˜¦ğ˜³ğ˜¢ğ˜¨ğ˜¦: Calculate the mean of these vectors to find the "center of gravity" for that class concept.

4ï¸âƒ£ ğ˜•ğ˜°ğ˜³ğ˜®ğ˜¢ğ˜­ğ˜ªğ˜»ğ˜¦: Re-normalize the averaged vector to unit length.

By averaging the embeddings, you marginalize out the noise of specific phrasing (e.g., ğ˜­ğ˜ªğ˜¨ğ˜©ğ˜µğ˜ªğ˜¯ğ˜¨, ğ˜´ğ˜µğ˜ºğ˜­ğ˜¦, ğ˜¤ğ˜°ğ˜®ğ˜±ğ˜°ğ˜´ğ˜ªğ˜µğ˜ªğ˜°ğ˜¯) and isolate the semantic signal of the object itself.

ğ“ğ¡ğ ğ€ğ§ğ¬ğ°ğğ« ğ“ğ¡ğšğ­ ğ†ğğ­ğ¬ ğ˜ğ¨ğ® ğ‡ğ¢ğ«ğğ:

"Single prompts are noisy estimates of a class. I would use ğ˜—ğ˜³ğ˜°ğ˜®ğ˜±ğ˜µ ğ˜Œğ˜¯ğ˜´ğ˜¦ğ˜®ğ˜£ğ˜­ğ˜ªğ˜¯ğ˜¨: generate multiple prompt templates for each class, average their embeddings to approximate the true class centroid, and use that stable vector for the dot-product classification."
