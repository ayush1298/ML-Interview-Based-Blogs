ğ—§ğ—µğ—² ğ—£ğ—²ğ—±ğ—²ğ˜€ğ˜ğ—¿ğ—¶ğ—®ğ—»-ğ—¦ğ—®ğ˜ƒğ—²ğ—¿ ğ—¦ğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—» ğŸš¶

You're in a Senior CV Engineer interview at Tesla and the interviewer sets a trap:

"ğ˜ğ˜¦ ğ˜¯ğ˜¦ğ˜¦ğ˜¥ ğ˜µğ˜° ğ˜µğ˜³ğ˜¢ğ˜¤ğ˜¬ ğ˜¢ ğ˜´ğ˜±ğ˜¦ğ˜¤ğ˜ªğ˜§ğ˜ªğ˜¤ ğ˜±ğ˜¦ğ˜¥ğ˜¦ğ˜´ğ˜µğ˜³ğ˜ªğ˜¢ğ˜¯ ğ˜¢ğ˜¤ğ˜³ğ˜°ğ˜´ğ˜´ 500 ğ˜§ğ˜³ğ˜¢ğ˜®ğ˜¦ğ˜´ ğ˜°ğ˜§ ğ˜·ğ˜ªğ˜¥ğ˜¦ğ˜° ğ˜§ğ˜°ğ˜³ ğ˜°ğ˜¶ğ˜³ ğ˜¢ğ˜¶ğ˜µğ˜°ğ˜¯ğ˜°ğ˜®ğ˜°ğ˜¶ğ˜´ ğ˜£ğ˜³ğ˜¢ğ˜¬ğ˜ªğ˜¯ğ˜¨ ğ˜´ğ˜ºğ˜´ğ˜µğ˜¦ğ˜®. ğ˜ğ˜°ğ˜¸ ğ˜¥ğ˜° ğ˜ºğ˜°ğ˜¶ ğ˜¥ğ˜¦ğ˜´ğ˜ªğ˜¨ğ˜¯ ğ˜µğ˜©ğ˜¦ ğ˜±ğ˜ªğ˜±ğ˜¦ğ˜­ğ˜ªğ˜¯ğ˜¦?"

90% of candidates walk right into the wall.

ğŸ—£ï¸ They say: "ğ˜Œğ˜¢ğ˜´ğ˜º. ğ˜'ğ˜­ğ˜­ ğ˜³ğ˜¶ğ˜¯ ğ˜ ğ˜–ğ˜“ğ˜–ğ˜·11 ğ˜°ğ˜¯ ğ˜¦ğ˜·ğ˜¦ğ˜³ğ˜º ğ˜§ğ˜³ğ˜¢ğ˜®ğ˜¦ ğ˜µğ˜° ğ˜¥ğ˜¦ğ˜µğ˜¦ğ˜¤ğ˜µ ğ˜±ğ˜¦ğ˜¥ğ˜¦ğ˜´ğ˜µğ˜³ğ˜ªğ˜¢ğ˜¯ğ˜´, ğ˜¢ğ˜¯ğ˜¥ ğ˜µğ˜©ğ˜¦ğ˜¯ ğ˜¶ğ˜´ğ˜¦ ğ˜¢ ğ˜’ğ˜¢ğ˜­ğ˜®ğ˜¢ğ˜¯ ğ˜ğ˜ªğ˜­ğ˜µğ˜¦ğ˜³ ğ˜°ğ˜³ ğ˜ğ˜¶ğ˜¯ğ˜¨ğ˜¢ğ˜³ğ˜ªğ˜¢ğ˜¯ ğ˜ˆğ˜­ğ˜¨ğ˜°ğ˜³ğ˜ªğ˜µğ˜©ğ˜® ğ˜µğ˜° ğ˜­ğ˜ªğ˜¯ğ˜¬ ğ˜µğ˜©ğ˜¦ ğ˜£ğ˜°ğ˜¶ğ˜¯ğ˜¥ğ˜ªğ˜¯ğ˜¨ ğ˜£ğ˜°ğ˜¹ğ˜¦ğ˜´ ğ˜¢ğ˜¤ğ˜³ğ˜°ğ˜´ğ˜´ ğ˜§ğ˜³ğ˜¢ğ˜®ğ˜¦ğ˜´ ğ˜£ğ˜¢ğ˜´ğ˜¦ğ˜¥ ğ˜°ğ˜¯ ğ˜ğ˜°ğ˜œ."

The interviewer stops you. "ğ˜ ğ˜°ğ˜¶ ğ˜«ğ˜¶ğ˜´ğ˜µ ğ˜¢ğ˜¥ğ˜¥ğ˜¦ğ˜¥ 200ğ˜®ğ˜´ ğ˜°ğ˜§ ğ˜­ğ˜¢ğ˜µğ˜¦ğ˜¯ğ˜¤ğ˜º ğ˜¢ğ˜¯ğ˜¥ ğ˜ºğ˜°ğ˜¶ğ˜³ ğ˜µğ˜³ğ˜¢ğ˜¤ğ˜¬ğ˜¦ğ˜³ ğ˜§ğ˜¢ğ˜ªğ˜­ğ˜´ ğ˜µğ˜©ğ˜¦ ğ˜®ğ˜°ğ˜®ğ˜¦ğ˜¯ğ˜µ ğ˜µğ˜©ğ˜¦ ğ˜±ğ˜¦ğ˜¥ğ˜¦ğ˜´ğ˜µğ˜³ğ˜ªğ˜¢ğ˜¯ ğ˜¸ğ˜¢ğ˜­ğ˜¬ğ˜´ ğ˜£ğ˜¦ğ˜©ğ˜ªğ˜¯ğ˜¥ ğ˜¢ ğ˜®ğ˜¢ğ˜ªğ˜­ğ˜£ğ˜°ğ˜¹."

The Reality:

â€¢ ğ—§ğ—µğ—² ğ—–ğ—¼ğ—»ğ˜€ğ—¶ğ˜€ğ˜ğ—²ğ—»ğ—°ğ˜† ğ—§ğ—¿ğ—®ğ—½: Running detection per-frame ignores the temporal reality. The model has ğ˜¢ğ˜®ğ˜¯ğ˜¦ğ˜´ğ˜ªğ˜¢. It doesn't know frame is related to frame .
â€¢ ğ—§ğ—µğ—² ğ—¢ğ—°ğ—°ğ—¹ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» ğ—™ğ—®ğ—¶ğ—¹ğ˜‚ğ—¿ğ—²: When an object disappears (occlusion), a frame-by-frame detector sees nothing. The Kalman filter predicts a straight line, but pedestrians don't move in straight lines.

âœ… The Solution: You don't need detection. You need ğ—¦ğ˜ğ—¿ğ—²ğ—®ğ—ºğ—¶ğ—»ğ—´ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜† ğ—¦ğ—²ğ—´ğ—ºğ—²ğ—»ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—».

You discard the "tracking-by-detection" paradigm. You use a ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜† ğ—•ğ—®ğ—»ğ—¸ ğ—”ğ—¿ğ—°ğ—µğ—¶ğ˜ğ—²ğ—°ğ˜ğ˜‚ğ—¿ğ—² (like SAM 2).

â€¢ ğ—œğ—»ğ—¶ğ˜ğ—¶ğ—®ğ—¹ğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—»: You prompt the target once in the first frame (click or box).
â€¢ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜† ğ—˜ğ—»ğ—°ğ—¼ğ—±ğ—²ğ—¿: The model stores this object's features in a "memory bank" (FIFO queue of high-res feature maps).
â€¢ ğ—£ğ—¿ğ—¼ğ—½ğ—®ğ—´ğ—®ğ˜ğ—¶ğ—¼ğ—»: For frame, the model attends both to the current image and the memory bank.

If the pedestrian vanishes behind a truck, the model doesn't "lose" them, it simply holds the memory pointer until they reappear, matching the re-emerged pixels against the stored memory context, not a heuristic bounding box.

âœï¸ ğ—§ğ—µğ—² ğ—”ğ—»ğ˜€ğ˜„ğ—²ğ—¿ ğ—§ğ—µğ—®ğ˜ ğ—šğ—²ğ˜ğ˜€ ğ—¬ğ—¼ğ˜‚ ğ—›ğ—¶ğ—¿ğ—²ğ—±:

"ğ˜›ğ˜³ğ˜¢ğ˜¤ğ˜¬ğ˜ªğ˜¯ğ˜¨ ğ˜£ğ˜º ğ˜¥ğ˜¦ğ˜µğ˜¦ğ˜¤ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜ªğ˜´ ğ˜£ğ˜³ğ˜ªğ˜µğ˜µğ˜­ğ˜¦. ğ˜ ğ˜¸ğ˜°ğ˜¶ğ˜­ğ˜¥ ğ˜ªğ˜®ğ˜±ğ˜­ğ˜¦ğ˜®ğ˜¦ğ˜¯ğ˜µ ğ˜¢ ğ™ˆğ™šğ™¢ğ™¤ğ™§ğ™®-ğ˜¼ğ™ªğ™œğ™¢ğ™šğ™£ğ™©ğ™šğ™™ ğ™ğ™šğ™œğ™¢ğ™šğ™£ğ™©ğ™–ğ™©ğ™ğ™¤ğ™£ ğ˜±ğ˜ªğ˜±ğ˜¦ğ˜­ğ˜ªğ˜¯ğ˜¦. ğ˜œğ˜´ğ˜ªğ˜¯ğ˜¨ ğ˜¢ğ˜¯ ğ˜¢ğ˜³ğ˜¤ğ˜©ğ˜ªğ˜µğ˜¦ğ˜¤ğ˜µğ˜¶ğ˜³ğ˜¦ ğ˜­ğ˜ªğ˜¬ğ˜¦ ğ˜šğ˜ˆğ˜” 2, ğ˜¸ğ˜¦ ğ˜µğ˜³ğ˜¦ğ˜¢ğ˜µ ğ˜·ğ˜ªğ˜¥ğ˜¦ğ˜° ğ˜¢ğ˜´ ğ˜¢ ğ˜¤ğ˜°ğ˜¯ğ˜µğ˜ªğ˜¯ğ˜¶ğ˜°ğ˜¶ğ˜´ ğ˜·ğ˜°ğ˜­ğ˜¶ğ˜®ğ˜¦, ğ˜¯ğ˜°ğ˜µ ğ˜¥ğ˜ªğ˜´ğ˜¤ğ˜³ğ˜¦ğ˜µğ˜¦ ğ˜´ğ˜­ğ˜ªğ˜¤ğ˜¦ğ˜´. ğ˜ğ˜¦ ğ˜®ğ˜¢ğ˜ªğ˜¯ğ˜µğ˜¢ğ˜ªğ˜¯ ğ˜¢ 'ğ˜´ğ˜µğ˜³ğ˜¦ğ˜¢ğ˜®ğ˜ªğ˜¯ğ˜¨ ğ˜®ğ˜¦ğ˜®ğ˜°ğ˜³ğ˜º' ğ˜°ğ˜§ ğ˜µğ˜©ğ˜¦ ğ˜°ğ˜£ğ˜«ğ˜¦ğ˜¤ğ˜µ'ğ˜´ ğ˜§ğ˜¦ğ˜¢ğ˜µğ˜¶ğ˜³ğ˜¦ğ˜´, ğ˜¢ğ˜­ğ˜­ğ˜°ğ˜¸ğ˜ªğ˜¯ğ˜¨ ğ˜¶ğ˜´ ğ˜µğ˜° ğ˜©ğ˜¢ğ˜¯ğ˜¥ğ˜­ğ˜¦ ğ˜©ğ˜¦ğ˜¢ğ˜·ğ˜º ğ˜°ğ˜¤ğ˜¤ğ˜­ğ˜¶ğ˜´ğ˜ªğ˜°ğ˜¯ ğ˜¢ğ˜¯ğ˜¥ ğ˜³ğ˜¦-ğ˜ªğ˜¥ğ˜¦ğ˜¯ğ˜µğ˜ªğ˜§ğ˜ªğ˜¤ğ˜¢ğ˜µğ˜ªğ˜°ğ˜¯ ğ˜¸ğ˜ªğ˜µğ˜©ğ˜°ğ˜¶ğ˜µ ğ˜©ğ˜¦ğ˜¶ğ˜³ğ˜ªğ˜´ğ˜µğ˜ªğ˜¤ğ˜´."
